{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyAthena in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (1.7.1)\n",
      "Requirement already satisfied: botocore>=1.5.52 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from PyAthena) (1.12.232)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from PyAthena) (0.17.1)\n",
      "Requirement already satisfied: boto3>=1.4.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from PyAthena) (1.9.232)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from PyAthena) (5.1.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (0.9.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (2.7.3)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (0.14)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (1.23)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3>=1.4.4->PyAthena) (0.2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tenacity>=4.1.0->PyAthena) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install PyAthena\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "conn = connect(s3_staging_dir='s3://aws-athena-query-results-984073016564-us-west-2/sagemaker', region_name='us-west-2')\n",
    "df = pd.read_sql(\"SELECT distinct * FROM retsdata.union_geo3 WHERE county = 'San Diego'\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(df):\n",
    "    return (df['streetnumber'].map(lambda s: '{!s:6.6}'.format(str(s))) + ' ' + \n",
    "       df['streetname'].map(lambda s: '{!s:20.20}'.format(s).upper()) + ' ' + \n",
    "       df['city'].map(lambda s: '{!s:16.16}'.format(s).upper()))\n",
    "\n",
    "df_train   = pad(df.loc[df['zip5'] != '0'])\n",
    "df_labels  = df['zip5'].map(str)\n",
    "df_predict = pad(df.loc[df['zip5'] == '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CODES = 128\n",
    "\n",
    "def encode(df):\n",
    "    sess = tf.Session()\n",
    "    v = df.map(lambda s: list(map(ord, list(s)))).values.tolist()\n",
    "    v = sess.run(list(map(lambda row: tf.one_hot(row, N_CODES), v)))\n",
    "    v = list(map(lambda v: [flatten for sub in v for flatten in sub], v))\n",
    "    return pd.Series(v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode(df_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET=1000\n",
    "train_inputs = encode(df_train[:SUBSET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = encode(df_labels[:SUBSET])\n",
    "train_labels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = len(train_inputs)\n",
    "INPUT_VAR_CODES = len(train_inputs[0])\n",
    "INPUT_VARS = INPUT_VAR_CODES // N_CODES\n",
    "OUTPUT_VAR_CODES = len(train_labels[0])\n",
    "OUTPUT_VARS = OUTPUT_VAR_CODES // N_CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[1, len(train_inputs[0])])\n",
    "Y = tf.placeholder(tf.float32, shape=[1, len(train_labels[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN=5\n",
    "parameters = {\n",
    "\t\t'W1': tf.Variable(tf.random_normal([len(train_inputs[0]), HIDDEN])),\n",
    "\t\t'b1': tf.Variable(tf.random_normal([HIDDEN])),\n",
    "\t\t'W2': tf.Variable(tf.random_normal([HIDDEN, len(train_labels[0])])),\n",
    "\t\t'b2': tf.Variable(tf.random_normal([len(train_labels[0])]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(X,parameters):\n",
    "\tZ1 = tf.add(tf.matmul(X, parameters['W1']), parameters['b1'])\n",
    "\tA2 = tf.nn.relu(Z1)\n",
    "\tZ2 = tf.add(tf.matmul(A2, parameters['W2']), parameters['b2'])\n",
    "\treturn Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def train():\n",
    "    print (datetime.datetime.now())\n",
    "    Z = neural_net(X,parameters)\n",
    "    costs = []\n",
    "    optimizers = []\n",
    "    for i in range(OUTPUT_VARS):\n",
    "        c = Z[0][N_CODES*i:N_CODES*i+N_CODES]\n",
    "        costs.append(tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=c,  labels=Y[0][N_CODES*i:N_CODES*i+N_CODES])))\n",
    "        optimizer_k = optimizers.append(tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(costs[i]))\n",
    "    optimizer = tf.group(*optimizers)\n",
    "    cost = tf.reduce_sum(costs)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        epoch = 0\n",
    "        while epoch<num_epochs:\n",
    "            for i in range(SAMPLES):\n",
    "                _ , c = sess.run([optimizer, cost], feed_dict={\n",
    "                    X: np.reshape(train_inputs[i],[1,INPUT_VAR_CODES]), \n",
    "                    Y: np.reshape(train_labels[i],[1,OUTPUT_VAR_CODES])\n",
    "                }) \n",
    "            if epoch % 200 == 0 or epoch == num_epochs:\n",
    "                print (str(datetime.datetime.now()) +  \" Cost after epoch %i: %f\" % (epoch, c))\n",
    "            epoch += 1\n",
    "        saver.save(sess, 'model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toheno(onehot):\n",
    "    # reverse the one-hot encoding\n",
    "    calcs = []\n",
    "    for i in range(len(onehot)//N_CODES):\n",
    "        charvec = onehot[N_CODES*i : N_CODES*(i+1)]\n",
    "        calcs.append(tf.argmax(charvec))\n",
    "    with tf.Session() as sess:\n",
    "        out = sess.run(calcs)\n",
    "    return ''.join([chr(i) for i in out])\n",
    "        \n",
    "toheno(train_inputs[0])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # Test predictions by computing the output using training set as input\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        saver = tf.train.import_meta_graph('model.ckpt.meta')\n",
    "        saver.restore(sess,'model.ckpt')\n",
    "        for row in range(len(train_inputs)):\n",
    "\n",
    "            g = train_inputs[row]\n",
    "            g = np.reshape(g,[1,INPUT_VAR_CODES])\n",
    "            output = neural_net(g,parameters)\n",
    "            outputs = []\n",
    "            for i in range(OUTPUT_VARS):\n",
    "                kk = tf.nn.softmax(output[0][N_CODES*i : N_CODES*i+N_CODES])\n",
    "                outputs.append(kk)\n",
    "                \n",
    "            \n",
    "            out = sess.run(outputs)\n",
    "            out = np.reshape(list(map(list,out)), [1, OUTPUT_VAR_CODES])[0].tolist()\n",
    "            out = list(map(lambda x: float(\"%.1f\" % x), out))\n",
    "            \n",
    "            print(\"\\nROW #\" + str(row))\n",
    "            print(\"Expected: \" + toheno(train_labels[row]))\n",
    "            print(\"Actual..: \" + toheno(out))            \n",
    "            row = row + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
